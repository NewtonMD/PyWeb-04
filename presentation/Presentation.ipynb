{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of an elderly woman at a keyboard exclaiming, \"If only I could find the price of cat food along my bus route, correlate it with the pension day weather, and see it on a map!\"](granny_mashup.png)\n",
    "\n",
    "<center>Paul Downey http://www.flickr.com/photos/psd/492139935/ - CC-BY</center>\n",
    "\n",
    "## Scraping, APIs and Mashups\n",
    "\n",
    "<table border=\"1\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>Week</strong></td>\n",
    "<td style=\"text-align: center;\"><strong>Topic(s)</strong></td>\n",
    "<td><strong>Assignment</strong></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>1</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>&nbsp;TCP/IP and Sockets</p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>2</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>Web Protocols</p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">2</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>3</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>CGI and WSGI<a class=\"headerlink\" title=\"Permalink to this headline\" href=\"http://uwpce-pythoncert.github.io/training.python_web/html/outline.html#session-3-cgi-and-wsgi\"></a></p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">3</td>\n",
    "</tr>\n",
    "<tr style=\"color:red;font-weight:bold\">\n",
    "<td style=\"text-align: center;\"><strong>4</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>APIs and Mashups</p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>5</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>MVC Applications and Data Persistence<a class=\"headerlink\" title=\"Permalink to this headline\" href=\"http://uwpce-pythoncert.github.io/training.python_web/html/outline.html#session-5-mvc-applications-and-data-persistence\"></a></p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">5</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>6</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>Pyramid Views, Renderers and Forms</p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">6</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>7</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>Pyramid Authentication and Deployment</p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">7</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>8</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>Basic Django</p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">8</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\"><strong>9</strong></td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>Extending Django</p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">9</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center;\">\n",
    "<p><strong>10</strong></p>\n",
    "</td>\n",
    "<td style=\"text-align: left;\">\n",
    "<p>Deploying Django</p>\n",
    "</td>\n",
    "<td style=\"text-align: center;\">Final Project</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "### Today\n",
    "\n",
    "Wherein we learn how to make order from the chaos of the wild internet.\n",
    "\n",
    "  1. Review of last week\n",
    "  2. Review of homework\n",
    "  3. What is a mashup?\n",
    "  4. the meme facter\n",
    "  5. The Secret Robot Internet (APIs)\n",
    "  6. Our own mashup.\n",
    "  7. Homework\n",
    "\n",
    "#### A Dilemma\n",
    "\n",
    "The internet makes a vast quantity of data available.\n",
    "\n",
    "But not always in the form or combination you want.\n",
    "\n",
    "It would be nice to be able to combine data from different sources to create meaning.\n",
    "\n",
    "The Big Question\n",
    "\n",
    "But How?\n",
    "\n",
    "The Big Answer\n",
    "\n",
    "Mashups\n",
    "\n",
    "Mashups\n",
    "\n",
    "A mashup is:\n",
    "\n",
    "```\n",
    "a web page, or web application, that uses and combines data, presentation\n",
    "or functionality from two or more sources to create new services.\n",
    "\n",
    "-- wikipedia (http://en.wikipedia.org/wiki/Mashup_(web_application_hybrid))\n",
    "```\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "The key to mashups is the idea of data sources.\n",
    "\n",
    "These come in many flavors:\n",
    "\n",
    "  * Simple websites with data in HTML\n",
    "  * Web services providing structured data\n",
    "  * Web services providing transformative service (geocoding)\n",
    "  * Web services providing presentation (mapping)\n",
    "\n",
    "### Web Scraping\n",
    "\n",
    "It would be nice if all online data were available in well-structured formats.\n",
    "\n",
    "The reality is that much data is available only in HTML.\n",
    "\n",
    "Still we can get at it, with some effort.\n",
    "\n",
    "By scraping the data from the web pages.\n",
    "\n",
    "#### HTML\n",
    "\n",
    "Ideally, it looks like this:\n",
    "\n",
    "```\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head></head>\n",
    "    <body>\n",
    "        <form>\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <td>Please type your name:</td>\n",
    "                    <td><input type=\"text\" name=\"input1\"></td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>Row 2 cell 1</td>\n",
    "                    <td>Row 2 cell 2<br>This</br> sure is a long cell</td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </form>\n",
    "    </body>\n",
    "</html>\n",
    "    \n",
    "```\n",
    "\n",
    "But in real life, it’s more often like this:\n",
    "\n",
    "```\n",
    "<html>\n",
    " <form>\n",
    "  <table>\n",
    "   <td><input name=\"input1\">Row 1 cell 1\n",
    "   <tr><td>Row 2 cell 1\n",
    "  </form>\n",
    "  <td>Row 2 cell 2<br>This</br> sure is a long cell\n",
    " </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "“Be strict in what you send and tolerant in what you receive”\n",
    "\n",
    "#### Taming the Mess\n",
    "\n",
    "Luckily, there are tools to help with this.\n",
    "\n",
    "In python there are several candidates, but I like BeautifulSoup.\n",
    "\n",
    "BeautifulSoup is a great tool, but it’s not in the Standard Library.\n",
    "\n",
    "We’ll need to install it.\n",
    "\n",
    "Create a virtualenv to do so:\n",
    "\n",
    "#### Intermezzo: Virtual Environments and Package Management in Python\n",
    "\n",
    "\n",
    "#### Back to our lesson!\n",
    "\n",
    "```\n",
    "$ pyvenv soupenv\n",
    "...\n",
    "$ source soupenv/bin/activate\n",
    "(remember, for Windows users that should be soupenv/Scripts/activate.bat)\n",
    "```\n",
    "\n",
    "Once the virtualenv is activated, you can simply use `pip` or `easy_install` to install the libraries you want:\n",
    "\n",
    "(soupenv)$ pip install beautifulsoup4\n",
    "BeautifulSoup is built to use the Python HTMLParser.\n",
    "\n",
    "Batteries Included. It’s already there\n",
    "It’s not great, especially before Python 2.7.3\n",
    "BeautifulSoup also supports using other parsers.\n",
    "\n",
    "There are two good choices: lxml and html5lib.\n",
    "\n",
    "lxml is better, but much harder to install. Let’s use html5lib.\n",
    "\n",
    "Again, this is pretty simple:\n",
    "\n",
    "(soupenv)$ pip install html5lib\n",
    "Once installed, BeautifulSoup will choose it automatically.\n",
    "\n",
    "BeautifulSoup will choose the “best” available.\n",
    "\n",
    "You can specify the parser if you need to for some reason.\n",
    "\n",
    "In fact, in recent versions of BeautifulSoup, you’ll be warned if you don’t (though you can ignore the warning).\n",
    "\n",
    "Python provides tools for opening urls and communicating with servers. It’s spread across the urllib and urllib2 packages.\n",
    "\n",
    "These packages have pretty unintuitive APIs.\n",
    "\n",
    "The requests library is becoming the de-facto standard for this type of work. Let’s install it too.\n",
    "\n",
    "```\n",
    "(soupenv)$ pip install requests\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Our Class Mashup\n",
    "\n",
    "We’ll be starting by scraping restaurant health code data for a given ZIP code\n",
    "\n",
    "Then, we’ll look up the geographic location of those zipcodes using Google\n",
    "\n",
    "Finally, we’ll display the results of our work on a map\n",
    "\n",
    "Start by opening a new file in your editor: mashup.py.\n",
    "\n",
    "The source for the data we’ll be displaying is a search tool provided by King County.\n",
    "\n",
    "It’s supposed to have a web service, but the service is broken.\n",
    "\n",
    "Luckily, the HTML search works just fine.\n",
    "\n",
    "Open the search form in your browser: http://info.kingcounty.gov/health/ehs/foodsafety/inspections/search.aspx\n",
    "\n",
    "Fill in a ZIP code (perhaps 98101).\n",
    "\n",
    "Add a start and end date (perhaps about 1 or 2 years apart).\n",
    "\n",
    "Submit the form, and take a look at what you get.\n",
    "\n",
    "Next we want to automate the process.\n",
    "\n",
    "Copy the domain and path of the url into your new mashup.py file like so:\n",
    "\n",
    "INSPECTION_DOMAIN = \"http://info.kingcounty.gov\"\n",
    "INSPECTION_PATH = \"/health/ehs/foodsafety/inspections/Results.aspx\"\n",
    "Next, copy the query parameters from the URL and convert them to a dictionary:\n",
    "\n",
    "INSPECTION_PARAMS = {\n",
    "    'Output': 'W',\n",
    "    'Business_Name': '',\n",
    "    'Business_Address': '',\n",
    "    'Longitude': '',\n",
    "    'Latitude': '',\n",
    "    'City': '',\n",
    "    'Zip_Code': '',\n",
    "    'Inspection_Type': 'All',\n",
    "    'Inspection_Start': '',\n",
    "    'Inspection_End': '',\n",
    "    'Inspection_Closed_Business': 'A',\n",
    "    'Violation_Points': '',\n",
    "    'Violation_Red_Points': '',\n",
    "    'Violation_Descr': '',\n",
    "    'Fuzzy_Search': 'N',\n",
    "    'Sort': 'H'\n",
    "}\n",
    "Fetching Search Results\n",
    "\n",
    "Next we’ll use the requests library to write a function to fetch these results on demand.\n",
    "\n",
    "In requests, each HTTP method has a module-level function:\n",
    "\n",
    "GET == requests.get(url, **kwargs)\n",
    "POST == requests.post(url, **kwargs)\n",
    "...\n",
    "kwargs represent other parts of an HTTP request:\n",
    "\n",
    "params: a dict of url parameters (?foo=bar&baz=bim)\n",
    "headers: a dict of headers to send with the request\n",
    "data: the body of the request, if any (form data for POST goes here)\n",
    "...\n",
    "The return value from one of these functions is a response object which provides:\n",
    "\n",
    "response.status_code: see the HTTP Status Code returned\n",
    "response.ok: True if response.status_code is not an error\n",
    "response.raise_for_status(): call to raise a python error if it is\n",
    "response.headers: The headers sent from the server\n",
    "response.text: Body of the response, decoded to unicode\n",
    "response.encoding: The encoding used to decode\n",
    "response.content: The original encoded response body as bytes\n",
    "requests documentation: http://docs.python-requests.org/en/latest/\n",
    "\n",
    "We’ll start by writing a function get_inspection_page\n",
    "\n",
    "It will accept keyword arguments for each of the possible query values\n",
    "It will build a dictionary of request query parameters from incoming keywords, using INSPECTION_PARAMS as a template\n",
    "It will make a request to the inspection service search page using this query\n",
    "It will return the encoded content and the encoding used as a tuple\n",
    "Try writing this function. Put it in mashup.py\n",
    "\n",
    "My Solution\n",
    "\n",
    "Here’s the one I created:\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_inspection_page(**kwargs):\n",
    "    url = INSPECTION_DOMAIN + INSPECTION_PATH\n",
    "    params = INSPECTION_PARAMS.copy()\n",
    "    for key, val in kwargs.items():\n",
    "        if key in INSPECTION_PARAMS:\n",
    "            params[key] = val\n",
    "    resp = requests.get(url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text\n",
    "Parse the Results\n",
    "\n",
    "Next, we’ll need to parse the results we get when we call that function\n",
    "\n",
    "But before we start, a word about parsing HTML with BeautifulSoup\n",
    "\n",
    "The BeautifulSoup object can be instantiated with a string or a file-like object as the sole argument:\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "parsed = BeautifulSoup('<h1>Some HTML</h1>')\n",
    "\n",
    "fh = open('a_page.html', 'r')\n",
    "parsed = BeautifulSoup(fh)\n",
    "\n",
    "page = urllib2.urlopen('http://site.com/page.html')\n",
    "parsed = BeautifulSoup(page)\n",
    "You might want to open the documentation as reference (http://www.crummy.com/software/BeautifulSoup/bs4/doc)\n",
    "\n",
    "My Solution\n",
    "\n",
    "Take a shot at writing this new function in mashup.py\n",
    "\n",
    "# add this import at the top\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# then add this function lower down\n",
    "def parse_source(html):\n",
    "    parsed = BeautifulSoup(html)\n",
    "    return parsed\n",
    "Put It Together\n",
    "\n",
    "We’ll need to make our script do something when run.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # do something\n",
    "Fetch a search results page\n",
    "Parse the resulting HTML\n",
    "For now, print out the results so we can see what we get\n",
    "Use the prettify method on a BeautifulSoup object:\n",
    "\n",
    "print(parsed.prettify())\n",
    "My Solution\n",
    "\n",
    "Try to come up with the proper code on your own. Add it to mashup.py\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    use_params = {\n",
    "        'Inspection_Start': '2/1/2013',\n",
    "        'Inspection_End': '2/1/2015',\n",
    "        'Zip_Code': '98101'\n",
    "    }\n",
    "    html = get_inspection_page(**use_params)\n",
    "    parsed = parse_source(html)\n",
    "    print(parsed.prettify())\n",
    "Assuming your virtualenv is still active, you should be able to execute the script.\n",
    "\n",
    "(soupenv)$ python mashup.py\n",
    "...\n",
    "   <script src=\"http://www.kingcounty.gov/kcscripts/kcPageAnalytics.js\" type=\"text/javascript\">\n",
    "   </script>\n",
    "   <script type=\"text/javascript\">\n",
    "     //<![CDATA[\n",
    "     var usasearch_config = { siteHandle:\"kingcounty\" };\n",
    "     var script = document.createElement(\"script\");\n",
    "     script.type = \"text/javascript\";\n",
    "     script.src = \"http://search.usa.gov/javascripts/remote.loader.js\";\n",
    "     document.getElementsByTagName(\"head\")[0].appendChild(script);\n",
    "     //]]>\n",
    "   </script>\n",
    "  </form>\n",
    " </body>\n",
    "</html>\n",
    "This script is available as resources/session04/mashup_1.py\n",
    "\n",
    "Now, let’s re-run the script, saving the output to a file so we can use it later:\n",
    "\n",
    "$ python mashup.py > inspection_page.html\n",
    "Then add a quick function to our script that will use these saved results:\n",
    "\n",
    "def load_inspection_page(name):\n",
    "    file_path = pathlib.Path(name)\n",
    "    return file_path.read_text(encoding='utf8')\n",
    "Finally, bolt that in to your script to use it:\n",
    "\n",
    "# COMMENT OUT THIS LINE AND REPLACE IT\n",
    "# html = get_inspection_page(**use_params)\n",
    "html = load_inspection_page('inspection_page.html')\n",
    "Extracting Data\n",
    "\n",
    "Next we find the bits of this pile of HTML that matter to us.\n",
    "\n",
    "Open the page you just wrote to disk in your web browser and open the developer tools to inspect the page source.\n",
    "\n",
    "You’ll want to start by finding the element in the page that contains all our search results.\n",
    "\n",
    "Look at the source and identify the single element we are looking for.\n",
    "\n",
    "Having found it visually, we can now search for it automatically. In BeautifulSoup:\n",
    "\n",
    "All HTML elements (including the parsed document itself) are tags\n",
    "A tag can be searched using its find or find_all methods\n",
    "This searches the descendents of the tag on which it is called.\n",
    "It takes arguments which act as filters on the search results\n",
    "like so:\n",
    "\n",
    "tag.find(name, attrs, recursive, text, **kwargs)\n",
    "tag.find_all(name, attrs, recursive, text, limit, **kwargs)\n",
    "The find method allows us to pass kwargs.\n",
    "\n",
    "Keywords that are not among the named parameters will be considered an HTML attribute.\n",
    "\n",
    "We can use this to find the column that holds our search results:\n",
    "\n",
    "content_col = parsed.find('td', id=\"contentcol\")\n",
    "Add that line to our mashup script and try it out:\n",
    "\n",
    "#...\n",
    "parsed = parse_source(html)\n",
    "content_col = parsed.find(\"td\", id=\"contentcol\")\n",
    "print content_col.prettify()\n",
    "(soupenv)$ python mashup.py\n",
    "<td id=\"contentcol\">\n",
    "    ...\n",
    "</td>\n",
    "The next job is to find the inspection data we can see when we click on the restaurant names in our page.\n",
    "\n",
    "Do you notice a pattern in how that data is structured?\n",
    "\n",
    "For each restaurant in our results, there are two <div> tags.\n",
    "\n",
    "The first contains the content you see at first, the second the content that displays when we click.\n",
    "\n",
    "What can you see that identifies these items?\n",
    "\n",
    "<div id=\"PR0084952\"...> and <div id=\"PR0084952~\"...>\n",
    "\n",
    "Each pair shares an ID, and the stuff we want is in the second one\n",
    "\n",
    "Each number is different for each restaurant\n",
    "\n",
    "We can use a regular expression to help us here.\n",
    "\n",
    "Let’s write a function in mashup.py that will find all the divs in our column with the right kind of id:\n",
    "\n",
    "It should match <div> tags only\n",
    "It should match ids that start with PR\n",
    "It should match ids that contain some number of digits after that\n",
    "It should match ids that end with a tilde (~) character\n",
    "# add an import up top\n",
    "import re\n",
    "\n",
    "# and add this function\n",
    "def restaurant_data_generator(html):\n",
    "    id_finder = re.compile(r'PR[\\d]+~')\n",
    "    return html.find_all('div', id=id_finder)\n",
    "Let’s add that step to the main block at the bottom of mashup.py (only print the first of the many divs that match):\n",
    "\n",
    "html, encoding = load_inspection_page('inspection_page.html')\n",
    "parsed = parse_source(html, encoding)\n",
    "content_col = parsed.find(\"td\", id=\"contentcol\")\n",
    "data_list = restaurant_data_generator(content_col)\n",
    "print data_list[0].prettify()\n",
    "Finally, test it out:\n",
    "\n",
    "(soupenv)$ python mashup.py\n",
    "<div id=\"PR0001203~\" name=\"PR0001203~\" onclick=\"toggleShow(this.id);\"...>\n",
    " <table style=\"width: 635px;\">\n",
    " ...\n",
    " </table>\n",
    "</div>\n",
    "This code is available as /resources/session04/mashup_2.py\n",
    "\n",
    "Parsing Restaurant Data\n",
    "\n",
    "Now that we have the records we want, we need to parse them.\n",
    "\n",
    "We’ll start by extracting information about the restaurants:\n",
    "\n",
    "Name\n",
    "Address\n",
    "Location\n",
    "How is this information contained in our records?\n",
    "\n",
    "Each record consists of a table with a series of rows (<tr>).\n",
    "\n",
    "The rows we want at this time all have two cells inside them.\n",
    "\n",
    "The first contains the label of the data, the second contains the value\n",
    "\n",
    "We’ll need a function in mashup.py that:\n",
    "\n",
    "takes an HTML element as an argument\n",
    "verifies that it is a <tr> element\n",
    "verifies that it has two immediate children that are <td> elements\n",
    "My solution:\n",
    "\n",
    "def has_two_tds(elem):\n",
    "    is_tr = elem.name == 'tr'\n",
    "    td_children = elem.find_all('td', recursive=False)\n",
    "    has_two = len(td_children) == 2\n",
    "    return is_tr and has_two\n",
    "Let’s try this out in an interpreter:\n",
    "\n",
    "In [1]: from mashup_3 import load_inspection_page, parse_source,\n",
    "        restaurant_data_generator, has_two_tds\n",
    "In [2]: html = load_inspection_page('inspection_page.html')\n",
    "In [3]: parsed = parse_source(html)\n",
    "...\n",
    "In [4]: content_col = parsed.find('td', id='contentcol')\n",
    "In [5]: records = restaurant_data_generator(content_col)\n",
    "In [6]: rec = records[4]\n",
    "We’d like to find all table rows in that div that contain two cells\n",
    "\n",
    "The table rows are all contained in a <tbody> tag.\n",
    "\n",
    "We only want the ones at the top of that tag (ones nested more deeply contain other data)\n",
    "\n",
    "In [13]: data_rows = rec.find('tbody').find_all(has_two_tds, recursive=False)\n",
    "In [14]: len(data_rows)\n",
    "Out[14]: 7\n",
    "In [15]: print(data_rows[0].prettify())\n",
    "<tr>\n",
    " <td class=\"promptTextBox\" style=\"width: 125px; font-weight: bold\">\n",
    "  - Business Name\n",
    " </td>\n",
    " <td class=\"promptTextBox\" style=\"width: 520px; font-weight: bold\">\n",
    "  SPICE ORIENT\n",
    " </td>\n",
    "</tr>\n",
    "Now we have a list of the rows that contain our data.\n",
    "\n",
    "Next we have to collect the data they contain\n",
    "\n",
    "The label/value structure of this data should suggest the right container to store the information.\n",
    "\n",
    "Let’s start by trying to get at the first label\n",
    "\n",
    "In [18]: row1 = data_rows[0]\n",
    "In [19]: cells = row1.find_all('td')\n",
    "In [20]: cell1 = cells[0]\n",
    "In [21]: cell1.text\n",
    "Out[21]: '\\n            - Business Name\\n           '\n",
    "That works well enough, but all that extra stuff is nasty\n",
    "\n",
    "We need a method to clean up the text we get from these cells\n",
    "\n",
    "It should strip extra whitespace, and characters like - and : we don’t want.\n",
    "\n",
    "Try writing such a function for yourself now in mashup.py\n",
    "\n",
    "def clean_data(td):\n",
    "    return td.text.strip(\" \\n:-\")\n",
    "Add it to your interpreter and test it out:\n",
    "\n",
    "In [25]: def clean_data(td):\n",
    "   ....:     return td.text.strip(\" \\n:-\")\n",
    "   ....:\n",
    "In [26]: clean_data(cell1)\n",
    "Out[26]: 'Business Name'\n",
    "In [27]:\n",
    "Ahhh, much better\n",
    "\n",
    "So we can get a list of the rows that contain label/value pairs.\n",
    "\n",
    "And we can extract clean values from the cells in these rows\n",
    "\n",
    "Now we need a function in mashup.py that will iterate through the rows we find and build a dictionary of the pairs.\n",
    "\n",
    "We have to be cautious because some rows don’t have a label.\n",
    "\n",
    "The values in these rows should go with the label from the previous row.\n",
    "\n",
    "Here’s the version I came up with:\n",
    "\n",
    "def extract_restaurant_metadata(elem):\n",
    "    restaurant_data_rows = elem.find('tbody').find_all(\n",
    "        has_two_tds, recursive=False\n",
    "    )\n",
    "    rdata = {}\n",
    "    current_label = ''\n",
    "    for data_row in restaurant_data_rows:\n",
    "        key_cell, val_cell = data_row.find_all('td', recursive=False)\n",
    "        new_label = clean_data(key_cell)\n",
    "        current_label = new_label if new_label else current_label\n",
    "        rdata.setdefault(current_label, []).append(clean_data(val_cell))\n",
    "    return rdata\n",
    "Add it to our script:\n",
    "\n",
    "# ...\n",
    "data_list = restaurant_data_generator(content_col)\n",
    "for data_div in data_list:\n",
    "    metadata = extract_restaurant_metadata(data_div)\n",
    "    print metadata\n",
    "And then try it out:\n",
    "\n",
    "```\n",
    "(soupenv)$ python mashup.py\n",
    "...\n",
    "{u'Business Category': [u'Seating 0-12 - Risk Category III'],\n",
    " u'Longitude': [u'122.3401786000'], u'Phone': [u'(206) 501-9554'],\n",
    " u'Business Name': [u\"ZACCAGNI'S\"], u'Address': [u'97B PIKE ST', u'SEATTLE, WA 98101'],\n",
    " u'Latitude': [u'47.6086651300']}\n",
    " ```\n",
    " \n",
    "This script is available as resources/session04/mashup_3.py\n",
    "\n",
    "\n",
    "Extracting Inspection Data\n",
    "\n",
    "The final step is to extract the inspection data for each restaurant.\n",
    "\n",
    "We want to capture only the score from each inspection, details we can leave behind.\n",
    "\n",
    "We’d like to calculate the average score for all known inspections.\n",
    "\n",
    "We’d also like to know how many inspections there were in total.\n",
    "\n",
    "Finally, we’d like to preserve the highest score of all inspections for a restaurant.\n",
    "\n",
    "We’ll add this information to our metadata about the restaurant.\n",
    "\n",
    "Let’s start by getting our bearings. Return to viewing the inspection_page.html you saved in a browser.\n",
    "\n",
    "Find a restaurant that has had an inspection or two.\n",
    "\n",
    "What can you say about the HTML that contains the scores for these inspections?\n",
    "\n",
    "I notice four characteristics that let us isolate the information we want:\n",
    "\n",
    "Inspection data is containd in <tr> elements\n",
    "Rows with inspection data in them have four <td> children\n",
    "The text in the first cell contains the word “inspection”\n",
    "But the text does not start with the word “inspection”\n",
    "Let’s try to write a filter function like the one above that will catch these rows for us.\n",
    "\n",
    "Add this new function is_inspection_data_row to mashup.py\n",
    "\n",
    "def is_inspection_data_row(elem):\n",
    "    is_tr = elem.name == 'tr'\n",
    "    if not is_tr:\n",
    "        return False\n",
    "    td_children = elem.find_all('td', recursive=False)\n",
    "    has_four = len(td_children) == 4\n",
    "    this_text = clean_data(td_children[0]).lower()\n",
    "    contains_word = 'inspection' in this_text\n",
    "    does_not_start = not this_text.startswith('inspection')\n",
    "    return is_tr and has_four and contains_word and does_not_start\n",
    "We can test this function by adding it into our script:\n",
    "\n",
    "for data_div in data_list:\n",
    "    metadata = extract_restaurant_metadata(data_div)\n",
    "    # UPDATE THIS BELOW HERE\n",
    "    inspection_rows = data_div.find_all(is_inspection_data_row)\n",
    "    print(metadata)\n",
    "    print(len(inspection_rows))\n",
    "    print('*'*10)\n",
    "And try running the script in your terminal:\n",
    "\n",
    "(soupenv)$ python mashup.py\n",
    "{u'Business Category': [u'Seating 0-12 - Risk Category III'],\n",
    " u'Longitude': [u'122.3401786000'], u'Phone': [u'(206) 501-9554'],\n",
    " u'Business Name': [u\"ZACCAGNI'S\"], u'Address': [u'97B PIKE ST', u'SEATTLE, WA 98101'],\n",
    " u'Latitude': [u'47.6086651300']}\n",
    "0\n",
    "**********\n",
    "Now we can isolate a list of the rows that contain inspection data.\n",
    "\n",
    "Next we need to calculate the average score, total number and highest score for each restaurant.\n",
    "\n",
    "Let’s add a function to mashup.py that will:\n",
    "\n",
    "Take a div containing a restaurant record\n",
    "Extract the rows containing inspection data\n",
    "Keep track of the highest score recorded\n",
    "Sum the total of all inspections\n",
    "Count the number of inspections made\n",
    "Calculate the average score for inspections\n",
    "Return the three calculated values in a dictionary\n",
    "Try writing this routine yourself.\n",
    "\n",
    "def get_score_data(elem):\n",
    "    inspection_rows = elem.find_all(is_inspection_data_row)\n",
    "    samples = len(inspection_rows)\n",
    "    total = high_score = average = 0\n",
    "    for row in inspection_rows:\n",
    "        strval = clean_data(row.find_all('td')[2])\n",
    "        try:\n",
    "            intval = int(strval)\n",
    "        except (ValueError, TypeError):\n",
    "            samples -= 1\n",
    "        else:\n",
    "            total += intval\n",
    "            high_score = intval if intval > high_score else high_score\n",
    "    if samples:\n",
    "        average = total/float(samples)\n",
    "    return {'Average Score': average, 'High Score': high_score,\n",
    "            'Total Inspections': samples}\n",
    "We can now incorporate this new routine into our mashup script.\n",
    "\n",
    "We’ll want to add the data it produces to the metadata we’ve already extracted.\n",
    "\n",
    "for data_div in data_list:\n",
    "    metadata = extract_restaurant_metadata(data_div)\n",
    "    inspection_data = get_score_data(data_div)\n",
    "    metadata.update(inspection_data)\n",
    "    print metadata\n",
    "And test it out at the command line:\n",
    "\n",
    "(soupenv)$ python mashup.py\n",
    "...\n",
    "{u'Business Category': [u'Seating 0-12 - Risk Category III'],\n",
    " u'Longitude': [u'122.3401786000'], u'High Score': 0,\n",
    " u'Phone': [u'(206) 501-9554'], u'Business Name': [u\"ZACCAGNI'S\"],\n",
    " u'Total Inspections': 0, u'Address': [u'97B PIKE ST', u'SEATTLE, WA 98101'],\n",
    " u'Latitude': [u'47.6086651300'], u'Average Score': 0}\n",
    "Break Time\n",
    "\n",
    "Once you have this working, take a break.\n",
    "\n",
    "When we return, we’ll try a saner approach to getting data from online\n",
    "\n",
    "Another Approach\n",
    "Scraping web pages is tedious and inherently brittle\n",
    "\n",
    "The owner of the website updates their layout, your code breaks\n",
    "\n",
    "But there is another way to get information from the web in a more normalized fashion\n",
    "\n",
    "Web Services\n",
    "\n",
    "Web Services\n",
    "\n",
    "“a software system designed to support interoperable machine-to-machine interaction over a network” - W3C\n",
    "\n",
    "provides a defined set of calls\n",
    "returns structured data\n",
    "RSS is one of the earliest forms of Web Services\n",
    "\n",
    "A single web-based endpoint provides a dynamically updated listing of content\n",
    "\n",
    "Implemented in pure HTTP. Returns XML\n",
    "\n",
    "Atom is a competing, but similar standard\n",
    "\n",
    "There’s a solid Python library for consuming RSS: feedparser.\n",
    "\n",
    "XML-RPC extended the essentially static nature of RSS by allowing users to call procedures and pass arguments.\n",
    "\n",
    "Calls are made via HTTP GET, by passing an XML document\n",
    "Returns from a call are sent to the client in XML\n",
    "In python, you can access XML-RPC services using xmlrpc from the standard library. It has two libraries, xmlrpc.client and xmlrpc.server\n",
    "\n",
    "SOAP extends XML-RPC in a couple of useful ways:\n",
    "\n",
    "It uses Web Services Description Language (WSDL) to provide meta-data about an entire service in a machine-readable format (Automatic introspection)\n",
    "It establishes a method for extending available data types using XML namespaces\n",
    "There is no standard library module that supports SOAP directly.\n",
    "\n",
    "The best-known and best-supported module available is Suds\n",
    "The homepage is https://fedorahosted.org/suds/\n",
    "It can be installed using easy_install or pip install\n",
    "A fork of the library compatible with Python 3 does exist\n",
    "I HATE SOAP\n",
    "\n",
    "SOAP was invented in part to provide completely machine-readable interoperability.\n",
    "\n",
    "Does that really work in real life?\n",
    "\n",
    "Hardly ever\n",
    "\n",
    "Another reason was to provide extensibility via custom types\n",
    "\n",
    "Does that really work in real life?\n",
    "\n",
    "Hardly ever\n",
    "\n",
    "In addition, XML is a pretty inefficient medium for transmitting data. There’s a lot of extra characters transmitted that lack any meaning.\n",
    "\n",
    "<?xml version=\"1.0\"?>\n",
    "<soap:Envelope xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\">\n",
    "  <soap:Header>\n",
    "  </soap:Header>\n",
    "  <soap:Body>\n",
    "    <m:GetStockPrice xmlns:m=\"http://www.example.org/stock/Surya\">\n",
    "      <m:StockName>IBM</m:StockName>\n",
    "    </m:GetStockPrice>\n",
    "  </soap:Body>\n",
    "</soap:Envelope>\n",
    "So, if neither of the original goals is really achieved by using SOAP\n",
    "\n",
    "And if the transmission medium is too bloated to use\n",
    "\n",
    "why pay all the overhead required to use the protocol?\n",
    "\n",
    "Is there another way we could consider approaching the problem?\n",
    "\n",
    "Enter REST\n",
    "\n",
    "REST\n",
    "\n",
    "Representational State Transfer\n",
    "\n",
    "Originally described by Roy T. Fielding (worth reading)\n",
    "Use HTTP for what it can do\n",
    "Read more in RESTful Web Services*\n",
    "* Seriously. Buy it and read it\n",
    "\n",
    "The XML-RCP/SOAP way:\n",
    "\n",
    "POST /getComment HTTP/1.1\n",
    "POST /getComments HTTP/1.1\n",
    "POST /addComment HTTP/1.1\n",
    "POST /editComment HTTP/1.1\n",
    "POST /deleteComment HTTP/1.1\n",
    "The RESTful way:\n",
    "\n",
    "GET /comment/<id> HTTP/1.1\n",
    "GET /comment HTTP/1.1\n",
    "POST /comment HTTP/1.1\n",
    "PUT /comment/<id> HTTP/1.1\n",
    "DELETE /comment/<id> HTTP/1.1\n",
    "REST is a Resource Oriented Architecture\n",
    "\n",
    "The URL represents the resource we are working with\n",
    "\n",
    "The HTTP Method indicates the action to be taken\n",
    "\n",
    "The HTTP Code returned tells us the result (whether success or failure)\n",
    "\n",
    "POST /comment HTTP/1.1 (creating a new comment):\n",
    "\n",
    "Success: HTTP/1.1 201 Created\n",
    "Failure (unauthorized): HTTP/1.1 401 Unauthorized\n",
    "Failure (NotImplemented): HTTP/1.1 405 Not Allowed\n",
    "Failure (ValueError): HTTP/1.1 406 Not Acceptable\n",
    "PUT /comment/<id> HTTP/1.1 (edit comment):\n",
    "\n",
    "Success: HTTP/1.1 200 OK\n",
    "Failure: HTTP/1.1 409 Conflict\n",
    "DELETE /comment/<id> HTTP/1.1 (delete comment):\n",
    "\n",
    "Success: HTTP/1.1 204 No Content\n",
    "REST uses JSON\n",
    "\n",
    "JavaScript Object Notation:\n",
    "\n",
    "a lightweight data-interchange format\n",
    "easy for humans to read and write\n",
    "easy for machines to parse and generate\n",
    "Based on Two Structures:\n",
    "\n",
    "object: { string: value, ...}\n",
    "array: [value, value, ]\n",
    "pythonic, no?\n",
    "\n",
    "JSON provides a few basic data types (see http://json.org/):\n",
    "\n",
    "string: unicode, anything but ”, \\ and control characters\n",
    "number: any number, but json does not use octal or hexadecimal\n",
    "object, array (we’ve seen these above)\n",
    "true\n",
    "false\n",
    "null\n",
    "No date type? OMGWTF??!!1!1\n",
    "\n",
    "You have two options:\n",
    "\n",
    "Option 1 - Unix Epoch Time (number):\n",
    "\n",
    ">>> import time\n",
    ">>> time.time()\n",
    "1358212616.7691269\n",
    "Option 2 - ISO 8661 (string):\n",
    "\n",
    ">>> import datetime\n",
    ">>> datetime.datetime.now().isoformat()\n",
    "'2013-01-14T17:18:10.727240'\n",
    "JSON in Python\n",
    "\n",
    "You can encode python to json, and decode json back to python:\n",
    "\n",
    "In [1]: import json\n",
    "In [2]: array = [1, 2, 3]\n",
    "In [3]: json.dumps(array)\n",
    "Out[3]: '[1, 2, 3]'\n",
    "In [4]: orig = {'foo': [1,2,3], 'bar': 'my resumé', 'baz': True}\n",
    "In [5]: encoded = json.dumps(orig)\n",
    "In [6]: encoded\n",
    "Out[6]: '{\"foo\": [1, 2, 3], \"bar\": \"my resum\\\\u00e9\", \"baz\": true}'\n",
    "In [7]: decoded = json.loads(encoded)\n",
    "In [8]: decoded == orig\n",
    "Out[8]: True\n",
    "Customizing the encoder or decoder class allows for specialized serializations\n",
    "\n",
    "the json module also supports reading and writing to file-like objects via json.dump(fp) and json.load(fp) (note the missing ‘s’)\n",
    "\n",
    "Remember duck-typing. Anything with a .write and a .read method is file-like\n",
    "\n",
    "This usage can be much more memory-friendly with large files/sources\n",
    "\n",
    "Playing With REST\n",
    "\n",
    "Let’s take a moment to play with REST.\n",
    "\n",
    "We’ll use a common, public API provided by Google.\n",
    "\n",
    "Geocoding\n",
    "\n",
    "https://developers.google.com/maps/documentation/geocoding\n",
    "\n",
    "Open a python interpreter using our virtualenv:\n",
    "\n",
    "(soupenv)$ python\n",
    "In [1]: import requests\n",
    "In [2]: import json\n",
    "In [3]: from pprint import pprint\n",
    "In [4]: url = 'http://maps.googleapis.com/maps/api/geocode/json'\n",
    "In [5]: addr = '1325 4th Ave, Seattle, 98101'\n",
    "In [6]: parameters = {'address': addr, 'sensor': 'false'}\n",
    "In [7]: resp = requests.get(url, params=parameters)\n",
    "In [8]: data = resp.json()\n",
    "You can do the same thing in reverse, supply latitude and longitude and get back address information:\n",
    "\n",
    "In [15]: if data['status'] == 'OK':\n",
    "   ....:     pprint(data['results'])\n",
    "   ....:\n",
    "[{'address_components': [{'long_name': '1325',\n",
    "                          'short_name': '1325',\n",
    "  ...\n",
    "  'types': ['street_address']}]\n",
    "Notice that there may be a number of results returned, ordered from most specific to least.\n",
    "\n",
    "Mashing It Up\n",
    "\n",
    "Google’s geocoding data is quite nice.\n",
    "\n",
    "But it’s not in a format we can use directly to create a map\n",
    "\n",
    "For that we need geojson\n",
    "\n",
    "Moreover, formatting the data for all those requests is going to get tedious.\n",
    "\n",
    "Luckily, people create wrappers for popular REST apis like google’s geocoding service.\n",
    "\n",
    "Once such wrapper is geocoder, which provides not only google’s service, but many others under a single umbrella.\n",
    "\n",
    "Install geocoder into your soupenv so that it’s available to use:\n",
    "\n",
    "(soupenv)$ pip install geocoder\n",
    "Our final step for tonight will be to geocode the results we have scraped from the inspection site.\n",
    "\n",
    "We’ll then convert that to geojson, insert our own properties and map the results.\n",
    "\n",
    "Let’s begin by converting our script so that what we have so far is contained in a generator function\n",
    "\n",
    "We’ll eventually sort our results and generate the top 10 or so for geocoding.\n",
    "\n",
    "Open up mashup.py and copy everthing in the main block.\n",
    "\n",
    "Add a new function result_generator to the mashup.py script. Paste the code you copied from the main block and then update it a bit:\n",
    "\n",
    "def result_generator(count):\n",
    "    use_params = {\n",
    "        'Inspection_Start': '2/1/2013',\n",
    "        'Inspection_End': '2/1/2015',\n",
    "        'Zip_Code': '98101'\n",
    "    }\n",
    "    # html, encoding = get_inspection_page(**use_params)\n",
    "    html, encoding = load_inspection_page('inspection_page.html')\n",
    "    parsed = parse_source(html, encoding)\n",
    "    content_col = parsed.find(\"td\", id=\"contentcol\")\n",
    "    data_list = restaurant_data_generator(content_col)\n",
    "    for data_div in data_list[:count]:\n",
    "        metadata = extract_restaurant_metadata(data_div)\n",
    "        inspection_data = get_score_data(data_div)\n",
    "        metadata.update(inspection_data)\n",
    "        yield metadata\n",
    "Update the main block of your mashup.py script to use the new function:\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for result in result_generator(10):\n",
    "        print result\n",
    "Then run your script and verify that the only thing that has changed is the number of results that print.\n",
    "\n",
    "(soupenv)$ python mashup.py\n",
    "# you should see 10 dictionaries print here.\n",
    "Add Geocoding\n",
    "\n",
    "The API for geocoding with geocoder is the same for all providers.\n",
    "\n",
    "You give an address, it returns geocoded data.\n",
    "\n",
    "You provide latitude and longitude, it provides address data\n",
    "\n",
    "In [1]: response = geocoder.google(<address>)\n",
    "In [2]: response.json\n",
    "Out[2]: # json result data\n",
    "In [3]: response.geojson\n",
    "Out[3]: # geojson result data\n",
    "Let’s add a new function get_geojson to mashup.py\n",
    "\n",
    "It will\n",
    "\n",
    "Take a result from our search as it’s input\n",
    "Get geocoding data from google using the address of the restaurant\n",
    "Return the geojson representation of that data\n",
    "Try to write this function on your own\n",
    "\n",
    "def get_geojson(result):\n",
    "    address = \" \".join(result.get('Address', ''))\n",
    "    if not address:\n",
    "        return None\n",
    "    geocoded = geocoder.google(address)\n",
    "    return geocoded.geojson\n",
    "Next, update our main block to get the geojson for each result and print it:\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for result in result_generator(10):\n",
    "        geojson = get_geojson(result)\n",
    "        print geojson\n",
    "Then test your results by running your script:\n",
    "\n",
    "(soupenv)$ python mashup.py\n",
    "{'geometry': {'type': 'Point', 'coordinates': [-122.3393005, 47.6134378]},\n",
    " 'type': 'Feature', 'properties': {'neighborhood': 'Belltown',\n",
    " 'encoding': 'utf-8', 'county': 'King County', 'city_long': 'Seattle',\n",
    " 'lng': -122.3393005, 'quality': u'street_address', 'city': 'Seattle',\n",
    " 'confidence': 9, 'state': 'WA', 'location': u'1933 5TH AVE SEATTLE, WA 98101',\n",
    " 'provider': 'google', 'housenumber': '1933', 'accuracy': 'ROOFTOP',\n",
    " 'status': 'OK', 'state_long': 'Washington',\n",
    " 'address': '1933 5th Avenue, Seattle, WA 98101, USA', 'lat': 47.6134378,\n",
    " 'postal': '98101', 'ok': True, 'road_long': '5th Avenue', 'country': 'US',\n",
    " 'country_long': 'United States', 'street': '5th Ave'},\n",
    " 'bbox': [-122.3406494802915, 47.6120888197085, -122.3379515197085, 47.6147867802915]}\n",
    "The properties of our geojson records are filled with data we don’t really care about.\n",
    "\n",
    "Let’s replace that information with some of the metadata from our inspection results.\n",
    "\n",
    "We’ll update our get_geojson function so that it:\n",
    "\n",
    "Builds a dictionary containing only the values we want from our inspection record.\n",
    "Converts list values to strings (geojson requires this)\n",
    "Replaces the ‘properties’ of our geojson with this new data\n",
    "Returns the modified geojson record\n",
    "See if you can make the updates on your own.\n",
    "\n",
    "def get_geojson(result):\n",
    "    # ...\n",
    "    geocoded = geocoder.google(address)\n",
    "    geojson = geocoded.geojson\n",
    "    inspection_data = {}\n",
    "    use_keys = (\n",
    "        'Business Name', 'Average Score', 'Total Inspections', 'High Score'\n",
    "    )\n",
    "    for key, val in result.items():\n",
    "        if key not in use_keys:\n",
    "            continue\n",
    "        if isinstance(val, list):\n",
    "            val = \" \".join(val)\n",
    "        inspection_data[key] = val\n",
    "    geojson['properties'] = inspection_data\n",
    "    return geojson\n",
    "We are now generating a series of geojson Feature objects.\n",
    "\n",
    "To map these objects, we’ll need to create a file which contains a geojson FeatureCollection.\n",
    "\n",
    "The structure of such a collection looks like this:\n",
    "\n",
    "{'type': 'FeatureCollection', 'features': [...]}\n",
    "Let’s update our main function to append each feature to such a structure.\n",
    "\n",
    "Then we can dump the structure as json to a file.\n",
    "\n",
    "In mashup.py update the main block like so:\n",
    "\n",
    "# add an import at the top:\n",
    "import json\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    total_result = {'type': 'FeatureCollection', 'features': []}\n",
    "    for result in result_generator(10):\n",
    "        geojson = get_geojson(result)\n",
    "        total_result['features'].append(geojson)\n",
    "    with open('my_map.json', 'w') as fh:\n",
    "        json.dump(total_result, fh)\n",
    "When you run the script nothing will print, but the new file will appear.\n",
    "\n",
    "(soupenv)$ python mashup.py\n",
    "This script is available as resources/session04/mashup_5.py\n",
    "\n",
    "Display the Results\n",
    "\n",
    "Once the new file is written you are ready to display your results.\n",
    "\n",
    "Open your web browser and go to http://geojson.io\n",
    "\n",
    "Then drag and drop the new file you wrote onto the map you see there.\n",
    "\n",
    "../_images/geojson-io.png\n",
    "Wrap Up\n",
    "\n",
    "We’ve built a simple mashup combining data from different sources.\n",
    "\n",
    "We scraped health inspection data from the King County government site.\n",
    "\n",
    "We geocoded that data.\n",
    "\n",
    "And we’ve displayed the results on a map.\n",
    "\n",
    "What other sources of data might we choose to combine?\n",
    "\n",
    "Check out programmable web to see some of the possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
